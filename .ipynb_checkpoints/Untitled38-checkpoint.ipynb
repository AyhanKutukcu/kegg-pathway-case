{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf2924-6226-455c-8ba0-946e98165356",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37521c2-12b1-4abf-9839-d0088411da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       converted_alias    mock_rep1    mock_rep2    mock_rep3  sars_cov_rep1  \\\n",
      "0      ENSG00000290825      0.03958      0.08353      0.08404        0.08911   \n",
      "1      ENSG00000278267      1.92300      3.04400      2.72200        2.16500   \n",
      "2      ENSG00000284332      0.00000      0.00000      0.00000        0.00000   \n",
      "3      ENSG00000237613      0.00000      0.00000      0.00000        0.00000   \n",
      "4      ENSG00000186092      0.00000      0.00000      0.00000        0.00000   \n",
      "...                ...          ...          ...          ...            ...   \n",
      "26114  ENSG00000212907   6446.00000   9613.00000  11580.00000     6564.00000   \n",
      "26115  ENSG00000198886  15420.00000  15630.00000  13400.00000    14620.00000   \n",
      "26116  ENSG00000198786   8609.00000   9019.00000   7286.00000     7628.00000   \n",
      "26117  ENSG00000198695  12270.00000  13240.00000  10410.00000    10550.00000   \n",
      "26118  ENSG00000198727   7928.00000   7369.00000   6012.00000     7487.00000   \n",
      "\n",
      "       sars_cov_rep2  sars_cov_rep3  \n",
      "0            0.08877        0.06094  \n",
      "1            2.15600        3.70100  \n",
      "2            0.00000        0.18240  \n",
      "3            0.00000        0.00000  \n",
      "4            0.00000        0.00000  \n",
      "...              ...            ...  \n",
      "26114     6939.00000     7220.00000  \n",
      "26115    16650.00000    15730.00000  \n",
      "26116     9205.00000     8384.00000  \n",
      "26117    12490.00000    11460.00000  \n",
      "26118     8709.00000     8027.00000  \n",
      "\n",
      "[26119 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TSV dosyasının yolunu belirtin\n",
    "dosya_yolu = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/assesment_dataset.tsv\"\n",
    "\n",
    "# TSV dosyasını oku\n",
    "df = pd.read_csv(dosya_yolu, sep='\\t')\n",
    "\n",
    "# Dosyanın içeriğini göster\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64cf0b49-5e4e-4fb0-954f-38a0f91aad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      converted_alias  mock_rep1  mock_rep2  mock_rep3  sars_cov_rep1  \\\n",
      "0     ENSG00000284662    0.01131    0.01194   0.008007        0.00000   \n",
      "1     ENSG00000291156    0.67130    0.49590   0.617700        1.20900   \n",
      "2     ENSG00000248333   16.24000   15.21000  15.690000       16.53000   \n",
      "3     ENSG00000169598    0.94210    0.79060   0.916000        1.11200   \n",
      "4     ENSG00000236423    0.10050    0.17670   0.118500        0.00000   \n",
      "...               ...        ...        ...        ...            ...   \n",
      "2066  ENSG00000183837    0.00000    0.00000   0.000000        0.01999   \n",
      "2067  ENSG00000102030   29.00000   28.37000  26.190000       34.02000   \n",
      "2068  ENSG00000207165   10.65000   10.73000   9.942000        9.81400   \n",
      "2069  ENSG00000071859   56.87000   59.30000  58.670000       71.24000   \n",
      "2070  ENSG00000182712    3.85900    3.91600   4.097000        3.42500   \n",
      "\n",
      "      sars_cov_rep2  sars_cov_rep3  \n",
      "0           0.00000       0.004354  \n",
      "1           0.97860       1.447000  \n",
      "2          17.31000      17.890000  \n",
      "3           1.14600       1.088000  \n",
      "4           0.07512       0.025790  \n",
      "...             ...            ...  \n",
      "2066        0.01991       0.034180  \n",
      "2067       30.51000      33.280000  \n",
      "2068        9.23300       9.321000  \n",
      "2069       66.68000      65.600000  \n",
      "2070        2.91300       3.485000  \n",
      "\n",
      "[2071 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TSV dosyasının yolunu belirtin\n",
    "dosya_yolu = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/anlamli_genler.tsv\"\n",
    "\n",
    "# TSV dosyasını oku\n",
    "df = pd.read_csv(dosya_yolu, sep='\\t')\n",
    "\n",
    "# Dosyanın içeriğini göster\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d85e6850-0350-44fc-92f7-c30d84c0f9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       converted_alias    mock_rep1    mock_rep2    mock_rep3  sars_cov_rep1  \\\n",
      "0      ENSG00000290825      0.03958      0.08353      0.08404        0.08911   \n",
      "1      ENSG00000278267      1.92300      3.04400      2.72200        2.16500   \n",
      "2      ENSG00000284332      0.00000      0.00000      0.00000        0.00000   \n",
      "5      ENSG00000290825      0.12210      0.04294      0.05760        0.04580   \n",
      "6      ENSG00000273874      0.96150      2.02900      0.68060        1.08200   \n",
      "...                ...          ...          ...          ...            ...   \n",
      "26114  ENSG00000212907   6446.00000   9613.00000  11580.00000     6564.00000   \n",
      "26115  ENSG00000198886  15420.00000  15630.00000  13400.00000    14620.00000   \n",
      "26116  ENSG00000198786   8609.00000   9019.00000   7286.00000     7628.00000   \n",
      "26117  ENSG00000198695  12270.00000  13240.00000  10410.00000    10550.00000   \n",
      "26118  ENSG00000198727   7928.00000   7369.00000   6012.00000     7487.00000   \n",
      "\n",
      "       sars_cov_rep2  sars_cov_rep3  \n",
      "0            0.08877        0.06094  \n",
      "1            2.15600        3.70100  \n",
      "2            0.00000        0.18240  \n",
      "5            0.13690        0.12530  \n",
      "6            1.07800        1.11000  \n",
      "...              ...            ...  \n",
      "26114     6939.00000     7220.00000  \n",
      "26115    16650.00000    15730.00000  \n",
      "26116     9205.00000     8384.00000  \n",
      "26117    12490.00000    11460.00000  \n",
      "26118     8709.00000     8027.00000  \n",
      "\n",
      "[20048 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Orijinal TSV dosyasının yolunu belirtin\n",
    "dosya_yolu = 'C:/Users/ayhan/Downloads/assesment_dataset_converter/assesment_dataset.tsv'\n",
    "\n",
    "# Orijinal dosyanın dizin yolunu al\n",
    "dizin_yolu = os.path.dirname(dosya_yolu)\n",
    "\n",
    "# Yeni dosya yolunu oluştur\n",
    "kopya_dosya_yolu = os.path.join(dizin_yolu, 'temizlenmis_dosya.tsv')\n",
    "\n",
    "# TSV dosyasını oku\n",
    "df = pd.read_csv(dosya_yolu, sep='\\t')\n",
    "\n",
    "# Sadece \"mock_rep1\", \"mock_rep2\", \"mock_rep3\", \"sars_cov_rep1\", \"sars_cov_rep2\", \"sars_cov_rep3\" sütunlarını içeren satırların hepsi 0 olan satırları çıkar\n",
    "sütunlar = [\"mock_rep1\", \"mock_rep2\", \"mock_rep3\", \"sars_cov_rep1\", \"sars_cov_rep2\", \"sars_cov_rep3\"]\n",
    "df = df[(df[sütunlar] != 0).any(axis=1)]\n",
    "\n",
    "# Temizlenmiş veri setini yeni bir TSV dosyasına kaydet\n",
    "df.to_csv(kopya_dosya_yolu, sep='\\t', index=False)\n",
    "\n",
    "# Temizlenmiş veri setini yazdır\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20c6a90-3f93-448c-a9c1-ca9ad78ff87e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(dosya_yolu, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Dosyanın içeriğini göster\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Doğru sütun adını kullanarak sütunu göster\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#print(df['converted_alias'])\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TSV dosyasının yolunu belirtin\n",
    "dosya_yolu = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/converter.tsv\"\n",
    "\n",
    "# TSV dosyasını oku\n",
    "df = pd.read_csv(dosya_yolu, sep='\\t')\n",
    "\n",
    "# Dosyanın içeriğini göster\n",
    "print(df[0])\n",
    "\n",
    "# Doğru sütun adını kullanarak sütunu göster\n",
    "#print(df['converted_alias'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "559cc1ef-78be-4cae-a8ac-5a203f9f67de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrelenmiş dosya C:/Users/ayhan/Downloads/assesment_dataset_converter/new_tsv.csv olarak başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TSV dosyasının yolunu belirtin\n",
    "input_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/converter.tsv\"\n",
    "temp_tsv_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/temp_tsv_file.tsv\"\n",
    "csv_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/new_tsv.csv\"\n",
    "\n",
    "\n",
    "# TSV dosyasını oku\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, open(temp_tsv_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        \n",
    "        # Satırı virgüle göre ayır\n",
    "        if \"None\" not in line:\n",
    "            columns = line.strip().split(',')\n",
    "            # \"None\" içeren satırları atla\n",
    "            # TSV formatında yeni dosyaya yaz\n",
    "            tsv_line = '\\t'.join(columns)\n",
    "            outfile.write(tsv_line + '\\n')\n",
    "        \n",
    "df = pd.read_csv(temp_tsv_file, sep='\\t', header=None)\n",
    "\n",
    "# Yeni CSV dosyasının yolunu belirtin\n",
    "\n",
    "# Filtrelenmiş DataFrame'i CSV dosyası olarak kaydet\n",
    "df.to_csv(csv_file, index=False, header=False)\n",
    "\n",
    "print(f\"Filtrelenmiş dosya {csv_file} olarak başarıyla kaydedildi.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19fabf21-40c1-446c-aa1a-498fbf94a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Güncellenmiş dosya C:/Users/ayhan/Downloads/assesment_dataset_converter/yeni_anlamli_genler.tsv olarak başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosya yollarını belirtin\n",
    "csv_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/new_tsv.csv\"\n",
    "anlamli_genler_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/anlamli_genler.tsv\"\n",
    "yeni_anlamli_genler = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/yeni_anlamli_genler.tsv\"\n",
    "\n",
    "# TSV dosyalarını oku\n",
    "anlamli_genler_df = pd.read_csv(anlamli_genler_file, sep='\\t')\n",
    "new_tsv_df = pd.read_csv(csv_file, header=None, names=[\"initial_alias\", \"converted_alias\", \"name\", \"description\", \"namespace\"])\n",
    "\n",
    "# initial_alias değerleri ile anlamli_genler_df'deki converted_alias değerlerini karşılaştır\n",
    "for index, row in new_tsv_df.iterrows():\n",
    "    match_index = anlamli_genler_df[anlamli_genler_df['converted_alias'] == row['converted_alias']].index\n",
    "    if not match_index.empty:\n",
    "        anlamli_genler_df.at[match_index[0], 'converted_alias'] = row['initial_alias']\n",
    "\n",
    "# Güncellenmiş DataFrame'i yeni TSV dosyasına yaz\n",
    "anlamli_genler_df.to_csv(yeni_anlamli_genler, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Güncellenmiş dosya {yeni_anlamli_genler} olarak başarıyla kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acf8301-a228-41cd-8270-05394298dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Güncellenmiş dosya C:/Users/ayhan/Downloads/assesment_dataset_converter/yeni_anlamli_genler.tsv olarak başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosya yolunu belirtin\n",
    "yeni_anlamli_genler_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/yeni_anlamli_genler.tsv\"\n",
    "\n",
    "# TSV dosyasını oku\n",
    "yeni_anlamli_genler_df = pd.read_csv(yeni_anlamli_genler_file, sep='\\t')\n",
    "\n",
    "# 'converted_alias' sütununda 'ENSG' içeren satırları sil\n",
    "filtered_df = yeni_anlamli_genler_df[~yeni_anlamli_genler_df['converted_alias'].str.contains('ENSG', na=False)]\n",
    "\n",
    "# Güncellenmiş DataFrame'i tekrar TSV dosyasına yaz\n",
    "filtered_df.to_csv(yeni_anlamli_genler_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Güncellenmiş dosya {yeni_anlamli_genler_file} olarak başarıyla kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e2b2aba-df44-4d25-921a-5b203af46efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene ENSG00000290825 için mock ve SARS-CoV grupları arasında anlamlı farklılık yoktur (p-value = 0.5776996762823065).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Veri çerçevesini oluşturalım (örnek veriye dayanarak)\n",
    "data = {\n",
    "    'converted_alias': ['ENSG00000290825', 'ENSG00000278267', 'ENSG00000284332'],\n",
    "    'mock_rep1': [0.03958, 1.923, 0.0],\n",
    "    'mock_rep2': [0.08353, 3.044, 0.0],\n",
    "    'mock_rep3': [0.08404, 2.722, 0.0],\n",
    "    'sars_cov_rep1': [0.08911, 2.165, 0.0],\n",
    "    'sars_cov_rep2': [0.08877, 2.156, 0.0],\n",
    "    'sars_cov_rep3': [0.06094, 3.701, 0.1824]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mock ve SARS-CoV grupları arasındaki farklı ifadeleri belirlemek için t-testi yapalım\n",
    "alpha = 0.05\n",
    "\n",
    "# Örnek olarak ilk gen için t-testi yapalım (ENSG00000290825)\n",
    "gene = 'ENSG00000290825'\n",
    "mock_expr = df.loc[df['converted_alias'] == gene, ['mock_rep1', 'mock_rep2', 'mock_rep3']].values.flatten()\n",
    "sars_cov_expr = df.loc[df['converted_alias'] == gene, ['sars_cov_rep1', 'sars_cov_rep2', 'sars_cov_rep3']].values.flatten()\n",
    "\n",
    "t_stat, p_val = ttest_ind(mock_expr, sars_cov_expr)\n",
    "\n",
    "# P-value kontrolü\n",
    "if p_val < alpha:\n",
    "    print(f\"Gene {gene} için mock ve SARS-CoV grupları arasında anlamlı farklılık vardır (p-value = {p_val}).\")\n",
    "else:\n",
    "    print(f\"Gene {gene} için mock ve SARS-CoV grupları arasında anlamlı farklılık yoktur (p-value = {p_val}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd345ba3-076d-4772-beb6-a8f59ef99c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold change hesaplandı ve C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_yeni_anlamli_genler.tsv dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosyayı oku\n",
    "file_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/yeni_anlamli_genler.tsv\"\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Fold change hesapla\n",
    "for i in range(1, 4):  # Toplam 3 mock ve 3 sars_cov sütunu var\n",
    "    mock_col = f'mock_rep{i}'\n",
    "    sars_cov_col = f'sars_cov_rep{i}'\n",
    "    fold_change_col = f'fold_change_rep{i}'\n",
    "    \n",
    "    df[fold_change_col] = (df[sars_cov_col] + 1e-6) / (df[mock_col] + 1e-6)  # Sıfıra bölme hatasını önlemek için küçük bir sayı ekliyoruz\n",
    "\n",
    "# Hesaplanan fold change'leri içeren dosyayı kaydet\n",
    "output_file = 'C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_yeni_anlamli_genler.tsv'\n",
    "df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f'Fold change hesaplandı ve {output_file} dosyasına kaydedildi.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "233ce134-20b2-4b8b-a9f9-6213c61c6ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Her satır için fold change değerleri hesaplandı ve C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_her_satir_icin.tsv dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosyayı oku\n",
    "file_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/yeni_anlamli_genler.tsv\"\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Her satır için fold change hesapla\n",
    "for index, row in df.iterrows():\n",
    "    mock_mean = row[['mock_rep1', 'mock_rep2', 'mock_rep3']].mean()\n",
    "    sars_cov_mean = row[['sars_cov_rep1', 'sars_cov_rep2', 'sars_cov_rep3']].mean()\n",
    "    \n",
    "    fold_change = (sars_cov_mean + 1e-6) / (mock_mean + 1e-6)  # Sıfıra bölme hatasını önlemek için küçük bir sayı ekliyoruz\n",
    "    \n",
    "    # Hesaplanan fold change değerini ilgili satıra yaz\n",
    "    df.at[index, 'fold_change'] = fold_change\n",
    "\n",
    "# Hesaplanan fold change'leri içeren dosyayı kaydet\n",
    "output_file = 'C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_her_satir_icin.tsv'\n",
    "df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f'Her satır için fold change değerleri hesaplandı ve {output_file} dosyasına kaydedildi.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73809020-bca6-4586-aee1-3b92b6287a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    source                                          term_name  \\\n",
      "100  GO:BP            cell surface receptor signaling pathway   \n",
      "122  GO:BP                        apoptotic signaling pathway   \n",
      "155  GO:BP                cytokine-mediated signaling pathway   \n",
      "168  GO:BP              extrinsic apoptotic signaling pathway   \n",
      "292  GO:BP          regulation of apoptotic signaling pathway   \n",
      "310  GO:BP              intrinsic apoptotic signaling pathway   \n",
      "416  GO:BP  regulation of extrinsic apoptotic signaling pa...   \n",
      "438  GO:BP   enzyme-linked receptor protein signaling pathway   \n",
      "452  GO:BP                              Wnt signaling pathway   \n",
      "524   KEGG                              TNF signaling pathway   \n",
      "526   KEGG                            IL-17 signaling pathway   \n",
      "527   KEGG                       NF-kappa B signaling pathway   \n",
      "546   REAC             TRAF3-dependent IRF activation pathway   \n",
      "551     WP        Network map of SARS CoV 2 signaling pathway   \n",
      "558     WP                     Nuclear receptors meta pathway   \n",
      "\n",
      "               term_id  highlighted  adjusted_p_value  \\\n",
      "100         GO:0007166        False      5.276017e-11   \n",
      "122         GO:0097190        False      1.795484e-09   \n",
      "155         GO:0019221        False      1.305929e-07   \n",
      "168         GO:0097191        False      3.504567e-07   \n",
      "292         GO:2001233        False      5.721278e-04   \n",
      "310         GO:0097193        False      1.337921e-03   \n",
      "416         GO:2001236        False      2.275177e-02   \n",
      "438         GO:0007167        False      3.056658e-02   \n",
      "452         GO:0016055        False      4.022774e-02   \n",
      "524         KEGG:04668        False      8.900891e-07   \n",
      "526         KEGG:04657        False      5.534697e-05   \n",
      "527         KEGG:04064        False      5.062964e-04   \n",
      "546  REAC:R-HSA-918233        False      2.835905e-02   \n",
      "551          WP:WP5115        False      9.914506e-04   \n",
      "558          WP:WP2882        False      1.205195e-02   \n",
      "\n",
      "     negative_log10_of_adjusted_p_value  term_size  query_size  \\\n",
      "100                           10.277694       2799        1749   \n",
      "122                            8.745818        607        1749   \n",
      "155                            6.884081        499        1749   \n",
      "168                            6.455366        228        1749   \n",
      "292                            3.242507        382        1749   \n",
      "310                            2.873570        315        1749   \n",
      "416                            1.642985        155        1749   \n",
      "438                            1.514753        967        1749   \n",
      "452                            1.395474        452        1749   \n",
      "524                            6.050566        113         892   \n",
      "526                            4.256906         92         892   \n",
      "527                            3.295595        102         892   \n",
      "546                            1.547308         15        1149   \n",
      "551                            3.003729        217         921   \n",
      "558                            1.918943        313         921   \n",
      "\n",
      "     intersection_size  effective_domain_size  \\\n",
      "100                341                  21031   \n",
      "122                104                  21031   \n",
      "155                 86                  21031   \n",
      "168                 50                  21031   \n",
      "292                 62                  21031   \n",
      "310                 53                  21031   \n",
      "416                 30                  21031   \n",
      "438                118                  21031   \n",
      "452                 64                  21031   \n",
      "524                 34                   8484   \n",
      "526                 27                   8484   \n",
      "527                 27                   8484   \n",
      "546                  8                  10842   \n",
      "551                 47                   8286   \n",
      "558                 58                   8286   \n",
      "\n",
      "                                         intersections  \n",
      "100  ENSG00000131697,ENSG00000116285,ENSG0000017160...  \n",
      "122  ENSG00000130939,ENSG00000126709,ENSG0000011676...  \n",
      "155  ENSG00000117115,ENSG00000117525,ENSG0000016071...  \n",
      "168  ENSG00000126709,ENSG00000023909,ENSG0000013424...  \n",
      "292  ENSG00000126709,ENSG00000116761,ENSG0000002390...  \n",
      "310  ENSG00000126709,ENSG00000213190,ENSG0000016322...  \n",
      "416  ENSG00000126709,ENSG00000023909,ENSG0000011658...  \n",
      "438  ENSG00000116285,ENSG00000171608,ENSG0000012670...  \n",
      "452  ENSG00000131697,ENSG00000178585,ENSG0000016240...  \n",
      "524  ENSG00000171608,ENSG00000073756,ENSG0000012553...  \n",
      "526  ENSG00000163220,ENSG00000143546,ENSG0000018433...  \n",
      "527  ENSG00000073756,ENSG00000125538,ENSG0000016942...  \n",
      "546  ENSG00000263528,ENSG00000115267,ENSG0000014683...  \n",
      "551  ENSG00000126709,ENSG00000137959,ENSG0000007375...  \n",
      "558  ENSG00000142583,ENSG00000117394,ENSG0000011617...  \n",
      "\"signal pathway\" kelimesini içeren satırlar C:/Users/ayhan/Downloads/assesment_dataset_converter/signal_path.csv dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosyayı oku\n",
    "file_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/gProfiler_hsapiens_09.07.2024 21-03-30__intersections.csv\"\n",
    "df = pd.read_csv(file_path, sep=',')\n",
    "\n",
    "# \"signal pathway\" kelimesini içeren satırları filtrele\n",
    "filtered_df = df[df[\"term_name\"].str.contains(\"pathway\", case=False, na=False)]\n",
    "print(filtered_df)\n",
    "\n",
    "# Filtrelenmiş veriyi signal_path.csv dosyasına kaydet\n",
    "output_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/signal_path.csv\"\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'\"signal pathway\" kelimesini içeren satırlar {output_file} dosyasına kaydedildi.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49389e1f-c04d-4a32-b424-d75fddc6637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rastgele seçilen renk: #FF9A33\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# RGB hex renk kodlarının bulunduğu liste\n",
    "hex_colors = [\n",
    "    \"#FF5733\", \"#33FF57\", \"#3357FF\", \"#FF33A8\", \"#33FFF1\",\n",
    "    \"#7D33FF\", \"#FF9A33\", \"#33FF4D\", \"#A833FF\", \"#FF5733\"\n",
    "]\n",
    "\n",
    "# Rastgele bir renk kodu seçen fonksiyon\n",
    "def pick_random_color(hex_colors, seed=None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    return random.choice(hex_colors)\n",
    "\n",
    "# Örnek kullanım\n",
    "seed_value = 6128  # Seed değeri\n",
    "random_color = pick_random_color(hex_colors, seed_value)\n",
    "print(f\"Rastgele seçilen renk: {random_color}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "938e2ff8-beba-4c68-a92e-98868ec3f3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"intersections\" sütunu güncellendi ve C:/Users/ayhan/Downloads/assesment_dataset_converter/signal_path.csv dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosyaları oku\n",
    "signal_path_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/signal_path.csv\"\n",
    "tmp_tsv_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/temp_tsv_file.tsv\"\n",
    "\n",
    "signal_path_df = pd.read_csv(signal_path_file)\n",
    "tmp_tsv_df = pd.read_csv(tmp_tsv_file, sep='\\t')\n",
    "\n",
    "# 'intersections' sütununu array'e al\n",
    "array_intersec = signal_path_df[\"intersections\"]\n",
    "\n",
    "# Güncellenmiş 'intersections' verilerini saklamak için bir liste oluştur\n",
    "updated_intersections = []\n",
    "\n",
    "for i in array_intersec:\n",
    "    array_tmp = []\n",
    "    tmp_str = \"\"\n",
    "    for j in i:\n",
    "        if j != ',':\n",
    "            tmp_str += j\n",
    "        else:\n",
    "            array_tmp.append(tmp_str.strip())\n",
    "            tmp_str = \"\"\n",
    "    array_tmp.append(tmp_str.strip())  # son değeri de ekle\n",
    "\n",
    "    # Değerleri karşılaştır ve eşleşenleri değiştir\n",
    "    updated_array = []\n",
    "    for item in array_tmp:\n",
    "        match = tmp_tsv_df[tmp_tsv_df['converted_alias'] == item]\n",
    "        if not match.empty:\n",
    "            updated_array.append(match['initial_alias'].values[0])\n",
    "        else:\n",
    "            updated_array.append(item)\n",
    "    \n",
    "    # Güncellenmiş değeri listeye ekle\n",
    "    updated_intersections.append(','.join(map(str, updated_array)))\n",
    "\n",
    "# Güncellenmiş 'intersections' sütununu DataFrame'e yaz\n",
    "signal_path_df['intersections'] = updated_intersections\n",
    "\n",
    "# Güncellenmiş DataFrame'i signal_path.csv dosyasına yaz\n",
    "signal_path_df.to_csv(signal_path_file, index=False)\n",
    "\n",
    "print(f'\"intersections\" sütunu güncellendi ve {signal_path_file} dosyasına kaydedildi.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f30a168c-9fa9-4576-ab9a-7127980c21f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4e4e4e\n",
      "#4e4e4e\n"
     ]
    }
   ],
   "source": [
    "# RGB hex renk kodlarının bulunduğu liste\n",
    "hex_colors = [\n",
    "    \"#000000\", \"#800000\", \"#008000\", \"#808000\", \"#000080\",\n",
    "    \"#800080\", \"#008080\", \"#c0c0c0\", \"#808080\", \"#ff0000\",\n",
    "    \"#00ff00\", \"#ffff00\", \"#0000ff\", \"#ff00ff\", \"#00ffff\",\n",
    "    \"#ffffff\", \"#000000\", \"#00005f\", \"#000087\", \"#0000af\",\n",
    "    \"#0000d7\", \"#0000ff\", \"#005f00\", \"#005f5f\", \"#005f87\",\n",
    "    \"#005faf\", \"#005fd7\", \"#005fff\", \"#008700\", \"#00875f\",\n",
    "    \"#008787\", \"#0087af\", \"#0087d7\", \"#0087ff\", \"#00af00\",\n",
    "    \"#00af5f\", \"#00af87\", \"#00afaf\", \"#00afd7\", \"#00afff\",\n",
    "    \"#00d700\", \"#00d75f\", \"#00d787\", \"#00d7af\", \"#00d7d7\",\n",
    "    \"#00d7ff\", \"#00ff00\", \"#00ff5f\", \"#00ff87\", \"#00ffaf\",\n",
    "    \"#00ffd7\", \"#00ffff\", \"#5f0000\", \"#5f005f\", \"#5f0087\",\n",
    "    \"#5f00af\", \"#5f00d7\", \"#5f00ff\", \"#5f5f00\", \"#5f5f5f\",\n",
    "    \"#5f5f87\", \"#5f5faf\", \"#5f5fd7\", \"#5f5fff\", \"#5f8700\",\n",
    "    \"#5f875f\", \"#5f8787\", \"#5f87af\", \"#5f87d7\", \"#5f87ff\",\n",
    "    \"#5faf00\", \"#5faf5f\", \"#5faf87\", \"#5fafaf\", \"#5fafd7\",\n",
    "    \"#5fafff\", \"#5fd700\", \"#5fd75f\", \"#5fd787\", \"#5fd7af\",\n",
    "    \"#5fd7d7\", \"#5fd7ff\", \"#5fff00\", \"#5fff5f\", \"#5fff87\",\n",
    "    \"#5fffaf\", \"#5fffd7\", \"#5fffff\", \"#870000\", \"#87005f\",\n",
    "    \"#870087\", \"#8700af\", \"#8700d7\", \"#8700ff\", \"#875f00\",\n",
    "    \"#875f5f\", \"#875f87\", \"#875faf\", \"#875fd7\", \"#875fff\",\n",
    "    \"#878700\", \"#87875f\", \"#878787\", \"#8787af\", \"#8787d7\",\n",
    "    \"#8787ff\", \"#87af00\", \"#87af5f\", \"#87af87\", \"#87afaf\",\n",
    "    \"#87afd7\", \"#87afff\", \"#87d700\", \"#87d75f\", \"#87d787\",\n",
    "    \"#87d7af\", \"#87d7d7\", \"#87d7ff\", \"#87ff00\", \"#87ff5f\",\n",
    "    \"#87ff87\", \"#87ffaf\", \"#87ffd7\", \"#87ffff\", \"#af0000\",\n",
    "    \"#af005f\", \"#af0087\", \"#af00af\", \"#af00d7\", \"#af00ff\",\n",
    "    \"#af5f00\", \"#af5f5f\", \"#af5f87\", \"#af5faf\", \"#af5fd7\",\n",
    "    \"#af5fff\", \"#af8700\", \"#af875f\", \"#af8787\", \"#af87af\",\n",
    "    \"#af87d7\", \"#af87ff\", \"#afaf00\", \"#afaf5f\", \"#afaf87\",\n",
    "    \"#afafaf\", \"#afafd7\", \"#afafff\", \"#afd700\", \"#afd75f\",\n",
    "    \"#afd787\", \"#afd7af\", \"#afd7d7\", \"#afd7ff\", \"#afff00\",\n",
    "    \"#afff5f\", \"#afff87\", \"#afffaf\", \"#afffd7\", \"#afffff\",\n",
    "    \"#d70000\", \"#d7005f\", \"#d70087\", \"#d700af\", \"#d700d7\",\n",
    "    \"#d700ff\", \"#d75f00\", \"#d75f5f\", \"#d75f87\", \"#d75faf\",\n",
    "    \"#d75fd7\", \"#d75fff\", \"#d78700\", \"#d7875f\", \"#d78787\",\n",
    "    \"#d787af\", \"#d787d7\", \"#d787ff\", \"#d7af00\", \"#d7af5f\",\n",
    "    \"#d7af87\", \"#d7afaf\", \"#d7afd7\", \"#d7afff\", \"#d7d700\",\n",
    "    \"#d7d75f\", \"#d7d787\", \"#d7d7af\", \"#d7d7d7\", \"#d7d7ff\",\n",
    "    \"#d7ff00\", \"#d7ff5f\", \"#d7ff87\", \"#d7ffaf\", \"#d7ffd7\",\n",
    "    \"#d7ffff\", \"#ff0000\", \"#ff005f\", \"#ff0087\", \"#ff00af\",\n",
    "    \"#ff00d7\", \"#ff00ff\", \"#ff5f00\", \"#ff5f5f\", \"#ff5f87\",\n",
    "    \"#ff5faf\", \"#ff5fd7\", \"#ff5fff\", \"#ff8700\", \"#ff875f\",\n",
    "    \"#ff8787\", \"#ff87af\", \"#ff87d7\", \"#ff87ff\", \"#ffaf00\",\n",
    "    \"#ffaf5f\", \"#ffaf87\", \"#ffafaf\", \"#ffafd7\", \"#ffafff\",\n",
    "    \"#ffd700\", \"#ffd75f\", \"#ffd787\", \"#ffd7af\", \"#ffd7d7\",\n",
    "    \"#ffd7ff\", \"#ffff00\", \"#ffff5f\", \"#ffff87\", \"#ffffaf\",\n",
    "    \"#ffffd7\", \"#ffffff\", \"#080808\", \"#121212\", \"#1c1c1c\",\n",
    "    \"#262626\", \"#303030\", \"#3a3a3a\", \"#444444\", \"#4e4e4e\",\n",
    "    \"#585858\", \"#606060\", \"#666666\", \"#767676\", \"#808080\",\n",
    "    \"#8a8a8a\", \"#949494\", \"#9e9e9e\", \"#a8a8a8\", \"#b2b2b2\",\n",
    "    \"#bcbcbc\", \"#c6c6c6\", \"#d0d0d0\", \"#dadada\", \"#e4e4e4\",\n",
    "    \"#eeeeee\"\n",
    "]\n",
    "\n",
    "# Rastgele bir renk kodu seçen fonksiyon\n",
    "def pick_random_color(hex_colors, seed=None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    return random.choice(hex_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e69a37fb-f767-4696-88f9-b6a6a3d9b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0007166\n",
      "GO:0097190\n",
      "GO:0019221\n",
      "GO:0097191\n",
      "GO:2001233\n",
      "GO:0097193\n",
      "GO:2001236\n",
      "GO:0007167\n",
      "GO:0016055\n",
      "KEGG:04668\n",
      "KEGG:04657\n",
      "KEGG:04064\n",
      "REAC:R-HSA-918233\n",
      "WP:WP5115\n",
      "WP:WP2882\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosyaları oku\n",
    "signal_path_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/signal_path.csv\"\n",
    "fold_change_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_her_satir_icin.tsv\"\n",
    "output_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/new_last.csv\"\n",
    "\n",
    "signal_path_df = pd.read_csv(signal_path_file)\n",
    "fold_change_df = pd.read_csv(fold_change_file, sep='\\t')\n",
    "\n",
    "array_intersec = signal_path_df[\"intersections\"]\n",
    "array_term_ids = signal_path_df[\"term_id\"]\n",
    "\n",
    "count = 0\n",
    "\n",
    "directory_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal\"\n",
    "fold_change_file_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_her_satir_icin.tsv\"\n",
    "\n",
    "fold_change_df = pd.read_csv(fold_change_file_path, sep=\"\\t\")\n",
    "#print(fold_change_df[\"converted_alias\"])\n",
    "#print(fold_change_df[\"fold_change\"])\n",
    "\n",
    "converted_alias_list = fold_change_df[\"converted_alias\"].tolist()\n",
    "index_of_value = converted_alias_list.index(100133612)\n",
    "\n",
    "while count < len(array_term_ids):  \n",
    "    print(array_term_ids[count])\n",
    "    str_name = array_term_ids[count]\n",
    "    str_name.replace(':', '')\n",
    "    file_name = f\"C:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal/{count}.txt\"\n",
    "    #file_content = array_term_ids[count] + \"\\t\\t\" + \"fold change\\n\"\n",
    "    file_content = array_term_ids[count] + \" rgb hex codes\\n\"\n",
    "    \n",
    "    array_temp = []\n",
    "    for i in array_intersec:\n",
    "        tmp_str = \"\"\n",
    "        array_tmp = []\n",
    "        for j in i:\n",
    "            if j != ',':\n",
    "                tmp_str += j\n",
    "            else:\n",
    "                array_tmp.append(tmp_str.strip())\n",
    "                tmp_str = \"\"\n",
    "        array_tmp.append(tmp_str.strip())  # son değeri de ekle\n",
    "        array_temp = array_tmp\n",
    "    for i in array_temp:\n",
    "        file_content = file_content + i + \" \"\n",
    "        index_of_value = converted_alias_list.index(int(i))\n",
    "        str_tmmmp = fold_change_df[\"fold_change\"][index_of_value]\n",
    "        rgb_hex_code_value = pick_random_color(hex_colors, int(i)) \n",
    "        \n",
    "        #file_content += str(str_tmmmp)\n",
    "        file_content += rgb_hex_code_value\n",
    "        file_content += \"\\n\"\n",
    "    \n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(file_content)\n",
    "        \n",
    "    #print(file_content)\n",
    "    file_content = \"\"\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ee14e-5280-4830-89dd-1d48c4c42a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dcdcb42-7e8f-4fe5-a3b1-f24d4c001c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal\\0.txt\n",
      "C:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal\\1.txt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '65180.5880811069624889\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     91\u001b[0m             tmp_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m---> 93\u001b[0m     rgb_hex_code_value \u001b[38;5;241m=\u001b[39m pick_random_color(hex_colors, \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtmp_str\u001b[49m\u001b[43m)\u001b[49m) \n\u001b[0;32m     94\u001b[0m     line \u001b[38;5;241m=\u001b[39m rgb_hex_code_value\n\u001b[0;32m     95\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '65180.5880811069624889\\n'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Dizinin yolu\n",
    "directory_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal\"\n",
    "fold_change_file_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_her_satir_icin.tsv\"\n",
    "\n",
    "# fold_change dosyasını yükleyelim\n",
    "fold_change_df = pd.read_csv(fold_change_file_path, sep=\"\\t\")\n",
    "\n",
    "# RGB hex renk kodlarının bulunduğu liste\n",
    "hex_colors = [\n",
    "    \"#000000\", \"#800000\", \"#008000\", \"#808000\", \"#000080\",\n",
    "    \"#800080\", \"#008080\", \"#c0c0c0\", \"#808080\", \"#ff0000\",\n",
    "    \"#00ff00\", \"#ffff00\", \"#0000ff\", \"#ff00ff\", \"#00ffff\",\n",
    "    \"#ffffff\", \"#000000\", \"#00005f\", \"#000087\", \"#0000af\",\n",
    "    \"#0000d7\", \"#0000ff\", \"#005f00\", \"#005f5f\", \"#005f87\",\n",
    "    \"#005faf\", \"#005fd7\", \"#005fff\", \"#008700\", \"#00875f\",\n",
    "    \"#008787\", \"#0087af\", \"#0087d7\", \"#0087ff\", \"#00af00\",\n",
    "    \"#00af5f\", \"#00af87\", \"#00afaf\", \"#00afd7\", \"#00afff\",\n",
    "    \"#00d700\", \"#00d75f\", \"#00d787\", \"#00d7af\", \"#00d7d7\",\n",
    "    \"#00d7ff\", \"#00ff00\", \"#00ff5f\", \"#00ff87\", \"#00ffaf\",\n",
    "    \"#00ffd7\", \"#00ffff\", \"#5f0000\", \"#5f005f\", \"#5f0087\",\n",
    "    \"#5f00af\", \"#5f00d7\", \"#5f00ff\", \"#5f5f00\", \"#5f5f5f\",\n",
    "    \"#5f5f87\", \"#5f5faf\", \"#5f5fd7\", \"#5f5fff\", \"#5f8700\",\n",
    "    \"#5f875f\", \"#5f8787\", \"#5f87af\", \"#5f87d7\", \"#5f87ff\",\n",
    "    \"#5faf00\", \"#5faf5f\", \"#5faf87\", \"#5fafaf\", \"#5fafd7\",\n",
    "    \"#5fafff\", \"#5fd700\", \"#5fd75f\", \"#5fd787\", \"#5fd7af\",\n",
    "    \"#5fd7d7\", \"#5fd7ff\", \"#5fff00\", \"#5fff5f\", \"#5fff87\",\n",
    "    \"#5fffaf\", \"#5fffd7\", \"#5fffff\", \"#870000\", \"#87005f\",\n",
    "    \"#870087\", \"#8700af\", \"#8700d7\", \"#8700ff\", \"#875f00\",\n",
    "    \"#875f5f\", \"#875f87\", \"#875faf\", \"#875fd7\", \"#875fff\",\n",
    "    \"#878700\", \"#87875f\", \"#878787\", \"#8787af\", \"#8787d7\",\n",
    "    \"#8787ff\", \"#87af00\", \"#87af5f\", \"#87af87\", \"#87afaf\",\n",
    "    \"#87afd7\", \"#87afff\", \"#87d700\", \"#87d75f\", \"#87d787\",\n",
    "    \"#87d7af\", \"#87d7d7\", \"#87d7ff\", \"#87ff00\", \"#87ff5f\",\n",
    "    \"#87ff87\", \"#87ffaf\", \"#87ffd7\", \"#87ffff\", \"#af0000\",\n",
    "    \"#af005f\", \"#af0087\", \"#af00af\", \"#af00d7\", \"#af00ff\",\n",
    "    \"#af5f00\", \"#af5f5f\", \"#af5f87\", \"#af5faf\", \"#af5fd7\",\n",
    "    \"#af5fff\", \"#af8700\", \"#af875f\", \"#af8787\", \"#af87af\",\n",
    "    \"#af87d7\", \"#af87ff\", \"#afaf00\", \"#afaf5f\", \"#afaf87\",\n",
    "    \"#afafaf\", \"#afafd7\", \"#afafff\", \"#afd700\", \"#afd75f\",\n",
    "    \"#afd787\", \"#afd7af\", \"#afd7d7\", \"#afd7ff\", \"#afff00\",\n",
    "    \"#afff5f\", \"#afff87\", \"#afffaf\", \"#afffd7\", \"#afffff\",\n",
    "    \"#d70000\", \"#d7005f\", \"#d70087\", \"#d700af\", \"#d700d7\",\n",
    "    \"#d700ff\", \"#d75f00\", \"#d75f5f\", \"#d75f87\", \"#d75faf\",\n",
    "    \"#d75fd7\", \"#d75fff\", \"#d78700\", \"#d7875f\", \"#d78787\",\n",
    "    \"#d787af\", \"#d787d7\", \"#d787ff\", \"#d7af00\", \"#d7af5f\",\n",
    "    \"#d7af87\", \"#d7afaf\", \"#d7afd7\", \"#d7afff\", \"#d7d700\",\n",
    "    \"#d7d75f\", \"#d7d787\", \"#d7d7af\", \"#d7d7d7\", \"#d7d7ff\",\n",
    "    \"#d7ff00\", \"#d7ff5f\", \"#d7ff87\", \"#d7ffaf\", \"#d7ffd7\",\n",
    "    \"#d7ffff\", \"#ff0000\", \"#ff005f\", \"#ff0087\", \"#ff00af\",\n",
    "    \"#ff00d7\", \"#ff00ff\", \"#ff5f00\", \"#ff5f5f\", \"#ff5f87\",\n",
    "    \"#ff5faf\", \"#ff5fd7\", \"#ff5fff\", \"#ff8700\", \"#ff875f\",\n",
    "    \"#ff8787\", \"#ff87af\", \"#ff87d7\", \"#ff87ff\", \"#ffaf00\",\n",
    "    \"#ffaf5f\", \"#ffaf87\", \"#ffafaf\", \"#ffafd7\", \"#ffafff\",\n",
    "    \"#ffd700\", \"#ffd75f\", \"#ffd787\", \"#ffd7af\", \"#ffd7d7\",\n",
    "    \"#ffd7ff\", \"#ffff00\", \"#ffff5f\", \"#ffff87\", \"#ffffaf\",\n",
    "    \"#ffffd7\", \"#ffffff\", \"#080808\", \"#121212\", \"#1c1c1c\",\n",
    "    \"#262626\", \"#303030\", \"#3a3a3a\", \"#444444\", \"#4e4e4e\",\n",
    "    \"#585858\", \"#606060\", \"#666666\", \"#767676\", \"#808080\",\n",
    "    \"#8a8a8a\", \"#949494\", \"#9e9e9e\", \"#a8a8a8\", \"#b2b2b2\",\n",
    "    \"#bcbcbc\", \"#c6c6c6\", \"#d0d0d0\", \"#dadada\", \"#e4e4e4\",\n",
    "    \"#eeeeee\"\n",
    "]\n",
    "\n",
    "# Rastgele bir renk kodu seçen fonksiyon\n",
    "def pick_random_color(hex_colors, seed=None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    return random.choice(hex_colors)\n",
    "\n",
    "# Tüm .txt dosyalarını döngüyle açacağız\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        print(file_path)\n",
    "        \n",
    "        # .txt dosyasını okuyup ve sonra yazma modunda açalım\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        count = 1 \n",
    "        with open(file_path, \"w\") as file:\n",
    "            for line in lines:\n",
    "                if count != 1:\n",
    "                    tmp_str = \"\"\n",
    "                    for i in line:\n",
    "                        if i != '\\t':\n",
    "                            tmp_str += i\n",
    "                            \n",
    "                    rgb_hex_code_value = pick_random_color(hex_colors, int(tmp_str)) \n",
    "                    line = rgb_hex_code_value\n",
    "                count = 0\n",
    "                file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34c087bc-d530-414a-be20-55b1b6957ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bioservices\n",
      "  Downloading bioservices-1.11.2.tar.gz (191 kB)\n",
      "     ---------------------------------------- 0.0/191.9 kB ? eta -:--:--\n",
      "     -------------- ------------------------ 71.7/191.9 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- --- 174.1/191.9 kB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 191.9/191.9 kB 1.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gseapy\n",
      "  Downloading gseapy-1.1.3-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: appdirs in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (1.4.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (4.11.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (6.7.0)\n",
      "Collecting easydev>=0.12.0 (from bioservices)\n",
      "  Downloading easydev-0.13.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting grequests (from bioservices)\n",
      "  Downloading grequests-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (3.7.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (2.31.0)\n",
      "Collecting requests_cache (from bioservices)\n",
      "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting suds-community>=0.7 (from bioservices)\n",
      "  Downloading suds_community-1.1.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (5.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (4.65.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (1.14.1)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bioservices) (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.13.0 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gseapy) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gseapy) (1.14.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from easydev>=0.12.0->bioservices) (0.4.6)\n",
      "Collecting colorlog (from bioservices)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting line-profiler<5.0.0,>=4.1.2 (from easydev>=0.12.0->bioservices)\n",
      "  Downloading line_profiler-4.1.3-cp311-cp311-win_amd64.whl.metadata (35 kB)\n",
      "Collecting pexpect<5.0.0,>=4.9.0 (from easydev>=0.12.0->bioservices)\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting platformdirs<5.0.0,>=4.2.0 (from easydev>=0.12.0->bioservices)\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (4.39.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->bioservices) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.21.1->bioservices) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.21.1->bioservices) (2023.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->bioservices) (2.4)\n",
      "Collecting gevent (from grequests->bioservices)\n",
      "  Downloading gevent-24.2.1-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->bioservices) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->bioservices) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->bioservices) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->bioservices) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=21.2 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests_cache->bioservices) (23.2.0)\n",
      "Collecting cattrs>=22.2 (from requests_cache->bioservices)\n",
      "  Downloading cattrs-23.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting url-normalize>=1.4 (from requests_cache->bioservices)\n",
      "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect<5.0.0,>=4.9.0->easydev>=0.12.0->bioservices)\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->bioservices) (1.16.0)\n",
      "Collecting zope.event (from gevent->grequests->bioservices)\n",
      "  Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting zope.interface (from gevent->grequests->bioservices)\n",
      "  Downloading zope.interface-6.4.post2-cp311-cp311-win_amd64.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.1/44.1 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting greenlet>=3.0rc3 (from gevent->grequests->bioservices)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: cffi>=1.12.2 in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gevent->grequests->bioservices) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ayhan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cffi>=1.12.2->gevent->grequests->bioservices) (2.21)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from zope.event->gevent->grequests->bioservices) (65.5.0)\n",
      "Downloading gseapy-1.1.3-cp311-cp311-win_amd64.whl (383 kB)\n",
      "   ---------------------------------------- 0.0/384.0 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 143.4/384.0 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 276.5/384.0 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 384.0/384.0 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading easydev-0.13.2-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.8/56.8 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading suds_community-1.1.2-py3-none-any.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.9 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 122.9/144.9 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 144.9/144.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading grequests-0.7.0-py2.py3-none-any.whl (5.7 kB)\n",
      "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.4/61.4 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading cattrs-23.2.3-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading line_profiler-4.1.3-cp311-cp311-win_amd64.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.6 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 92.2/126.6 kB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 126.6/126.6 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.8/63.8 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
      "Downloading gevent-24.2.1-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.8 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 112.6/292.8 kB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 225.3/292.8 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 292.8/292.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading zope.interface-6.4.post2-cp311-cp311-win_amd64.whl (206 kB)\n",
      "   ---------------------------------------- 0.0/206.4 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 122.9/206.4 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 206.4/206.4 kB 2.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: bioservices\n",
      "  Building wheel for bioservices (setup.py): started\n",
      "  Building wheel for bioservices (setup.py): finished with status 'done'\n",
      "  Created wheel for bioservices: filename=bioservices-1.11.2-py3-none-any.whl size=223290 sha256=7cbbdfa330e71bd932d59975ba63e84cf181879c476daccbded9b1cad0ec96c6\n",
      "  Stored in directory: c:\\users\\ayhan\\appdata\\local\\pip\\cache\\wheels\\7f\\99\\8b\\4bad72b741806a29f19ee46b1483ceb7498f8d07df2286a986\n",
      "Successfully built bioservices\n",
      "Installing collected packages: ptyprocess, zope.interface, zope.event, url-normalize, suds-community, platformdirs, pexpect, line-profiler, greenlet, colorlog, cattrs, requests_cache, gevent, easydev, gseapy, grequests, bioservices\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 2.6.2\n",
      "    Uninstalling platformdirs-2.6.2:\n",
      "      Successfully uninstalled platformdirs-2.6.2\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 2.0.2\n",
      "    Uninstalling greenlet-2.0.2:\n",
      "      Successfully uninstalled greenlet-2.0.2\n",
      "  Attempting uninstall: colorlog\n",
      "    Found existing installation: colorlog 6.7.0\n",
      "    Uninstalling colorlog-6.7.0:\n",
      "      Successfully uninstalled colorlog-6.7.0\n",
      "Successfully installed bioservices-1.11.2 cattrs-23.2.3 colorlog-6.8.2 easydev-0.13.2 gevent-24.2.1 greenlet-3.0.3 grequests-0.7.0 gseapy-1.1.3 line-profiler-4.1.3 pexpect-4.9.0 platformdirs-4.2.2 ptyprocess-0.7.0 requests_cache-1.2.1 suds-community-1.1.2 url-normalize-1.4.3 zope.event-5.0 zope.interface-6.4.post2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyscript 0.2.5 requires platformdirs<3.0.0,>=2.5.2, but you have platformdirs 4.2.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\ayhan\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bioservices gseapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fec4d8e-e6fc-4aa5-bd5a-3aa585a017c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Warning: No enrich terms when cutoff = 0.05",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal/0.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_change\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# KEGG analizini gerçekleştir\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m enr \u001b[38;5;241m=\u001b[39m \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menrichr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgene_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mgene_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKEGG_2016\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                 \u001b[49m\u001b[43morganism\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHuman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnrichr_results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# p-değeri eşik değerini 0.05 olarak ayarladık\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Sonuçları incele\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(enr\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gseapy\\__init__.py:554\u001b[0m, in \u001b[0;36menrichr\u001b[1;34m(gene_list, gene_sets, organism, outdir, background, cutoff, format, figsize, top_term, no_plot, verbose)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# set organism\u001b[39;00m\n\u001b[0;32m    553\u001b[0m enr\u001b[38;5;241m.\u001b[39mset_organism()\n\u001b[1;32m--> 554\u001b[0m \u001b[43menr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gseapy\\enrichr.py:633\u001b[0m, in \u001b[0;36mEnrichr.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# plotting\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__no_plot:\n\u001b[1;32m--> 633\u001b[0m         ax \u001b[38;5;241m=\u001b[39m \u001b[43mbarplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_term\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__top_term\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msalmon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m            \u001b[49m\u001b[43mofname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtxt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate figures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gseapy\\plot.py:1266\u001b[0m, in \u001b[0;36mbarplot\u001b[1;34m(df, column, group, title, cutoff, top_term, figsize, color, ofname, **kwargs)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbarplot\u001b[39m(\n\u001b[0;32m   1237\u001b[0m     df: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[0;32m   1238\u001b[0m     column: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdjusted P-value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1247\u001b[0m ):\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Visualize GSEApy Results.\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;124;03m    When multiple datasets exist in the input dataframe, the `group` argument is your friend.\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03m             Only terms with `column` <= `cut-off` are plotted.\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1266\u001b[0m     dot \u001b[38;5;241m=\u001b[39m \u001b[43mDotPlot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# x turns into hue in bar\u001b[39;49;00m\n\u001b[0;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTerm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# hue turns into x in bar\u001b[39;49;00m\n\u001b[0;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_terms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtop_term\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mviridis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# placeholder only\u001b[39;49;00m\n\u001b[0;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mofname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mofname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(color, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1279\u001b[0m         color \u001b[38;5;241m=\u001b[39m [color]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gseapy\\plot.py:649\u001b[0m, in \u001b[0;36mDotPlot.__init__\u001b[1;34m(self, df, x, y, hue, dot_scale, x_order, y_order, thresh, n_terms, title, figsize, cmap, ofname, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_terms \u001b[38;5;241m=\u001b[39m n_terms\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresh \u001b[38;5;241m=\u001b[39m thresh\n\u001b[1;32m--> 649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf.fonttype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m42\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps.fonttype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m42\u001b[39m})\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gseapy\\plot.py:674\u001b[0m, in \u001b[0;36mDotPlot.process\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    673\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: No enrich terms when cutoff = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresh\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbar_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolname\n\u001b[0;32m    676\u001b[0m \u001b[38;5;66;03m# clip GSEA lower bounds\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# if self.colname in [\"NOM p-val\", \"FDR q-val\"]:\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;66;03m#     df[self.colname].clip(1e-5, 1.0, inplace=True)\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# sorting the dataframe for better visualization\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Warning: No enrich terms when cutoff = 0.05"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gseapy as gp\n",
    "from bioservices.kegg import KEGG\n",
    "\n",
    "# Veriyi yükle\n",
    "data = pd.read_csv(\"C:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal/0.txt\", sep=\"\\t\", header=None, names=[\"GO\", \"fold_change\"])\n",
    "\n",
    "# KEGG analizini gerçekleştir\n",
    "enr = gp.enrichr(gene_list=data[\"GO\"].astype(str).tolist(),\n",
    "                 gene_sets='KEGG_2016',\n",
    "                 organism='Human',\n",
    "                 outdir='Enrichr_results',\n",
    "                 cutoff=0.05)  # p-değeri eşik değerini 0.05 olarak ayarladık\n",
    "\n",
    "# Sonuçları incele\n",
    "print(enr.results.head())\n",
    "\n",
    "# KEGG pathway bilgilerini al\n",
    "kegg = KEGG()\n",
    "pathways = kegg.pathwayIds\n",
    "\n",
    "for pathway in pathways:\n",
    "    info = kegg.get(pathway)\n",
    "    print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30747b72-13de-4081-a299-8ac8a4ea0c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#SİLİNECEK\n",
    "# Dizinin yolu\n",
    "directory_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/sinyal\"\n",
    "fold_change_file_path = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/fold_change_her_satir_icin.tsv\"\n",
    "\n",
    "# fold_change dosyasını yükleyelim\n",
    "fold_change_df = pd.read_csv(fold_change_file_path, sep=\"\\t\")\n",
    "#print(fold_change_df[\"converted_alias\"])\n",
    "#print(fold_change_df[\"fold_change\"])\n",
    "\n",
    "# Convert the \"converted_alias\" column to a list and find the index of the specified value\n",
    "converted_alias_list = fold_change_df[\"converted_alias\"].tolist()\n",
    "index_of_value = converted_alias_list.index(100133612)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9340247-2afa-4c7f-a241-f21d4e928e1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m mock_expr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(row[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmock_rep1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmock_rep2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmock_rep3\u001b[39m\u001b[38;5;124m'\u001b[39m]], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     19\u001b[0m sars_cov_expr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(row[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msars_cov_rep1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msars_cov_rep2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msars_cov_rep3\u001b[39m\u001b[38;5;124m'\u001b[39m]], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m---> 21\u001b[0m t_stat, p_val \u001b[38;5;241m=\u001b[39m \u001b[43mttest_ind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_expr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msars_cov_expr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# P-value kontrolü\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p_val \u001b[38;5;241m<\u001b[39m alpha:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_axis_nan_policy.py:522\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    520\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(sample\u001b[38;5;241m.\u001b[39mravel()) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m     axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(axis)\n\u001b[0;32m    524\u001b[0m     n_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_axis_nan_policy.py:50\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[1;34m(arrays, axis, xp)\u001b[0m\n\u001b[0;32m     48\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [xp\u001b[38;5;241m.\u001b[39masarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m     49\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m---> 50\u001b[0m new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m [new_shapes]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrays)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_axis_nan_policy.py:92\u001b[0m, in \u001b[0;36m_broadcast_shapes\u001b[1;34m(shapes, axis)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AxisError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`axis` must contain only distinct elements\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m     removed_shapes \u001b[38;5;241m=\u001b[39m new_shapes[:, axis]\n\u001b[1;32m---> 92\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# If arrays are broadcastable, shape elements that are 1 may be replaced\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# with a corresponding non-1 shape element. Assuming arrays are\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# broadcastable, that final shape element can be found with:\u001b[39;00m\n\u001b[0;32m     97\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(new_shapes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\function_base.py:5169\u001b[0m, in \u001b[0;36m_delete_dispatcher\u001b[1;34m(arr, obj, axis)\u001b[0m\n\u001b[0;32m   5164\u001b[0m         output \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output]\n\u001b[0;32m   5166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m-> 5169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_delete_dispatcher\u001b[39m(arr, obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   5170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (arr, obj)\n\u001b[0;32m   5173\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_delete_dispatcher)\n\u001b[0;32m   5174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete\u001b[39m(arr, obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "# Dosyayı oku\n",
    "file_path = r\"C:\\Users\\ayhan\\Downloads\\assesment_dataset_converter\\temizlenmis_dosya.tsv\"\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# P-value eşiği\n",
    "alpha = 0.05\n",
    "\n",
    "# Anlamlı farklılıkları tutacak bir liste oluşturalım\n",
    "significant_genes = []\n",
    "\n",
    "# Her bir gen için differential expression analizini yapalım\n",
    "for index, row in df.iterrows():\n",
    "    gene = row['converted_alias']\n",
    "    mock_expr = pd.to_numeric(row[['mock_rep1', 'mock_rep2', 'mock_rep3']], errors='coerce').dropna()\n",
    "    sars_cov_expr = pd.to_numeric(row[['sars_cov_rep1', 'sars_cov_rep2', 'sars_cov_rep3']], errors='coerce').dropna()\n",
    "    \n",
    "    t_stat, p_val = ttest_ind(mock_expr, sars_cov_expr)\n",
    "    \n",
    "    # P-value kontrolü\n",
    "    if p_val < alpha:\n",
    "        \n",
    "        significant_genes.append(gene)  # Anlamlı olan genleri listeye ekle\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57531910-f794-4ae6-bbcc-c5f0cb808e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anlamlı genler içeren dosya kaydedildi: C:\\Users\\ayhan\\Downloads\\assesment_dataset_converter\\anlamli_genler.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "# Dosyayı oku\n",
    "file_path = r\"C:\\Users\\ayhan\\Downloads\\assesment_dataset_converter\\temizlenmis_dosya.tsv\"\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# P-value eşiği\n",
    "alpha = 0.05\n",
    "\n",
    "# Anlamlı farklılıkları tutacak bir liste oluşturalım\n",
    "significant_genes = []\n",
    "\n",
    "# Her bir gen için differential expression analizini yapalım\n",
    "for index, row in df.iterrows():\n",
    "    gene = row['converted_alias']\n",
    "    mock_expr = pd.to_numeric(row[['mock_rep1', 'mock_rep2', 'mock_rep3']], errors='coerce').dropna()\n",
    "    sars_cov_expr = pd.to_numeric(row[['sars_cov_rep1', 'sars_cov_rep2', 'sars_cov_rep3']], errors='coerce').dropna()\n",
    "    \n",
    "    t_stat, p_val = ttest_ind(mock_expr, sars_cov_expr)\n",
    "    \n",
    "    # P-value kontrolü\n",
    "    if p_val < alpha:\n",
    "        significant_genes.append(row)  # Anlamlı olan genin satırını listeye ekle\n",
    "    \n",
    "# Anlamlı genleri içeren yeni veri çerçevesini oluştur\n",
    "significant_df = pd.DataFrame(significant_genes)\n",
    "\n",
    "# Yeni dosyayı kaydet\n",
    "output_file_path = r\"C:\\Users\\ayhan\\Downloads\\assesment_dataset_converter\\anlamli_genler.tsv\"\n",
    "significant_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Anlamlı genler içeren dosya kaydedildi: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "714b1e2d-04d1-4bce-a6ab-8bb342bdfb86",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m ensembl_id_to_find \u001b[38;5;241m=\u001b[39m significant_genes_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# converter.tsv dosyasında ilgili sütunu bul\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m matched_rows \u001b[38;5;241m=\u001b[39m converter_df[\u001b[43mconverter_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m ensembl_id_to_find]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Eşleşme varsa ilk satırı al, yoksa uyarı ver\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matched_rows\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1690\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1690\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1691\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1692\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:966\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    970\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1592\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(key):\n\u001b[1;32m-> 1592\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;66;03m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;66;03m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Anlamlı genlerin bulunduğu TSV dosyasını okuyun\n",
    "significant_genes_file = r'C:/Users/ayhan/Downloads/assesment_dataset_converter/anlamli_genler.tsv'\n",
    "significant_genes_df = pd.read_csv(significant_genes_file, sep='\\t')\n",
    "\n",
    "# Converter.tsv dosyasını okuyun\n",
    "converter_file = r'C:/Users/ayhan/Downloads/assesment_dataset_converter/converter.tsv'\n",
    "converter_df = pd.read_csv(converter_file, sep='\\t')\n",
    "\n",
    "# anlamli_genler.tsv dosyasının ikinci sütununun ilk satırındaki değeri al\n",
    "ensembl_id_to_find = significant_genes_df.iloc[0, 1]\n",
    "\n",
    "# converter.tsv dosyasında ilgili sütunu bul\n",
    "matched_rows = converter_df[converter_df.iloc[:, 1] == ensembl_id_to_find]\n",
    "\n",
    "# Eşleşme varsa ilk satırı al, yoksa uyarı ver\n",
    "if not matched_rows.empty:\n",
    "    matched_row = matched_rows.iloc[0]\n",
    "    # anlamli_genler.tsv dosyasının ilgili satırına Ensembl ID'yi yaz\n",
    "    significant_genes_df.at[0, 'initial_alias'] = matched_row.iloc[1]  # İkinci sütunun değerini alıyoruz\n",
    "else:\n",
    "    print(f\"Uyarı: {ensembl_id_to_find} değeri için eşleşme bulunamadı.\")\n",
    "\n",
    "# Yeni dosya adı ve yolu\n",
    "output_file = 'updated_anlamli_genler.tsv'\n",
    "\n",
    "# Güncellenmiş DataFrame'i TSV dosyası olarak kaydet\n",
    "significant_genes_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Güncellenmiş dosya kaydedildi: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "912a4cf2-5269-43fb-8546-dc727ecd696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ayhan/Downloads/assesment_dataset_converter/converter.tsv dosyası C:/Users/ayhan/Downloads/assesment_dataset_converter/converter.csv olarak başarıyla dönüştürüldü.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TSV dosyasının yolunu belirtin\n",
    "tsv_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/converter.tsv\"\n",
    "\n",
    "# TSV dosyasını oku\n",
    "df = pd.read_csv(tsv_file, sep='\\t')\n",
    "\n",
    "# CSV dosyasının yolunu belirleyin\n",
    "csv_file = \"C:/Users/ayhan/Downloads/assesment_dataset_converter/converter.csv\"\n",
    "\n",
    "# DataFrame'i CSV dosyası olarak kaydet\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"{tsv_file} dosyası {csv_file} olarak başarıyla dönüştürüldü.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f15d2a2-1423-42ef-aaa8-1f18cd2f862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
      "<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\n",
      "<eSearchResult><Count>1</Count><RetMax>1</RetMax><RetStart>0</RetStart><IdList>\n",
      "<Id>100302278</Id>\n",
      "</IdList><TranslationSet/><TranslationStack>   <TermSet>    <Term>ENSG00000284332[All Fields]</Term>    <Field>All Fields</Field>    <Count>1</Count>    <Explode>N</Explode>   </TermSet>   <OP>GROUP</OP>  </TranslationStack><QueryTranslation>ENSG00000284332[All Fields]</QueryTranslation><ErrorList><FieldNotFound>Source ID</FieldNotFound></ErrorList></eSearchResult>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_entrez_id(ensembl_id):\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=gene&term={ensembl_id}[Source+ID]\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "ensembl_id = \"ENSG00000284332\"\n",
    "entrez_id = get_entrez_id(ensembl_id)\n",
    "print(entrez_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8de7c-04c4-4ba1-80ae-469d5f33c88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
